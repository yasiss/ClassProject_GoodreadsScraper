{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e16b849",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# www.goodreads.com web scraper\n",
    "\n",
    "The initial set up (placeholder) of this repository was forked from CS410Assignments/CourseProject, holder for UIUC CS 410 - Text Transformation Systems, Fall 2021, Final Project.\n",
    "\n",
    "I will write a web scaper with Python to scrape Goodreads website, using Selenium and BeautifulSoup\n",
    "\n",
    "**Overview** \n",
    "<br />\n",
    "<br />This Project is a GoodReads website scraper that take all the newreleases by month and genre in last 2 years from the website and gather the information about them and display the 5 highest rating ones.\n",
    "\n",
    "The content can be used for book recommandations and annual blog posts.\n",
    "\n",
    "**Methods**\n",
    "<br />\n",
    "<br />The Web scaraper was written with:\n",
    "- Python\n",
    "- on JupiterNotbook\n",
    "- Using Selenium and Beautifulsoup\n",
    "\n",
    "Presentation is done with:\n",
    "\n",
    "- HTML\n",
    "- D3.js \n",
    "\n",
    "### The website for the Visualization\n",
    "https://yasiss.github.io/CourseProject_GoodreadsScraper/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e10afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package everything together\n",
    "#1\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "#Ctrl+] to indent\n",
    "def login():\n",
    "\n",
    "    url      = 'https://www.goodreads.com/'\n",
    "    username = 'youremail@hotmail.com'\n",
    "    password = '*********'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.ESCAPE)\n",
    "    time.sleep(1)\n",
    "\n",
    "    #driver.find_element(By.CLASS_NAME,'gr-hyperlink').click()\n",
    "    driver.find_element(By.LINK_TEXT, 'Sign In').click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_element(By.ID,'user_email').send_keys(username)\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.ID,'user_password').send_keys(password)\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_element(By.NAME,'next').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47049005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "serv = Service(\"C:/Users/yasi_/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "driver = webdriver.Chrome(service = serv)\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2d7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "\n",
    "def process_books(html,y):\n",
    "    #books = soup.find_all('div',{'class':'cover'}) #find the whole page info\n",
    "    genres = soup.find_all('tr',{'class':'genre'}) #find the whole page info\n",
    "    #genres = soup.find_all('div',{'class':'genre_releases'})\n",
    "    clean_book_list = []\n",
    "    \n",
    "    \n",
    "    for genre in genres:        \n",
    "\n",
    "        books = genre.find_all('div',{'class':'book'})\n",
    "        for book in books:\n",
    "            data_dict = {}\n",
    "            names_genres = genre.find('div',{'class':'name'})\n",
    "            data_dict['book_url'] = book.a['href'] #we get the url and break it down and put in the dictionary\n",
    "            data_dict['title'] = book.a['title'].strip()\n",
    "            data_dict['genre'] = names_genres.find('h3').getText()\n",
    "            data_dict['author'] = ''\n",
    "            data_dict['rating'] = ''\n",
    "            data_dict['pages'] = ''\n",
    "            data_dict['description'] = ''\n",
    "            data_dict['year'] = y\n",
    "            data_dict['published'] = ''\n",
    "   \n",
    "          #  data_dict['img_src'] = book.img['src']\n",
    "\n",
    "            clean_book_list.append(data_dict)\n",
    "        #break  #just firsr record\n",
    "    return clean_book_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab0eda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2020\n",
      "Month:  1\n",
      "Month:  2\n",
      "Month:  3\n",
      "Month:  4\n",
      "Month:  5\n",
      "Month:  6\n",
      "Month:  7\n",
      "Month:  8\n",
      "Month:  9\n",
      "Month:  10\n",
      "Month:  11\n",
      "Month:  12\n",
      "Year:  2021\n",
      "Month:  1\n",
      "Month:  2\n",
      "Month:  3\n",
      "Month:  4\n",
      "Month:  5\n",
      "Month:  6\n",
      "Month:  7\n",
      "Month:  8\n",
      "Month:  9\n",
      "Month:  10\n",
      "Month:  11\n",
      "Month:  12\n"
     ]
    }
   ],
   "source": [
    "master_list_books = []\n",
    "\n",
    "for j in range(2020,2022):\n",
    "    print('Year: ', j)\n",
    "    for i in range(1, 13):\n",
    "        print('Month: ', i) #it starts from 0\n",
    "        driver.get(f'https://www.goodreads.com/new_releases/{j}/{i}?tab=by_genre')\n",
    "    \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        clean_book_list = process_books(html,j)\n",
    "\n",
    "        master_list_books.extend(clean_book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca728a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Create a dataframe for our data\n",
    "df_books = pd.DataFrame(master_list_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27209063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_list_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905e56da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of books scraped so far:  100\n",
      "No of books scraped so far:  200\n",
      "No of books scraped so far:  300\n",
      "No of books scraped so far:  400\n",
      "No of books scraped so far:  500\n",
      "No of books scraped so far:  600\n",
      "No of books scraped so far:  700\n",
      "No of books scraped so far:  800\n",
      "No of books scraped so far:  1000\n",
      "No of books scraped so far:  1100\n",
      "No of books scraped so far:  1200\n"
     ]
    }
   ],
   "source": [
    "#### Scraping information of each book using for loop ####\n",
    "\n",
    "#creating a loop counter\n",
    "i = 0\n",
    "\n",
    "#Loop through all 50 books\n",
    "for url in df_books.iloc[:, 0]:\n",
    "    \n",
    "    #connect to url page\n",
    "    note_resp = requests.get(url)\n",
    "    \n",
    "    #checking if the request is successful\n",
    "    if note_resp.status_code == 200:\n",
    "        #print(\"URL{}: {}\".format(i+1, url))\n",
    "        pass\n",
    "    else:\n",
    "        #print('Status code{}: Skipping URL #{}: {}'.format(note_resp.status_code, i+1, url))\n",
    "        i = i+1\n",
    "        continue\n",
    "    \n",
    "    #get HTML from url page\n",
    "    note_html = note_resp.content\n",
    "    \n",
    "    #create beautifulsoup object for url page\n",
    "    note_soup = BeautifulSoup(note_html, 'html.parser')\n",
    "    \n",
    "    #Extract Author particulars\n",
    "    author_divs = note_soup.find_all('div', {'class':'authorName__container'})\n",
    "    try:\n",
    "        author_text = author_divs[0].find_all('a')[0].text\n",
    "    except IndexError:\n",
    "        author_text = 'Nil'\n",
    "    \n",
    "    #Extract rating particulars\n",
    "    rating_divs = note_soup.find_all(\"div\", {\"class\": \"uitext stacked\", \"id\": \"bookMeta\"})\n",
    "    try:\n",
    "        rating_text = rating_divs[0].find_all(\"span\", {\"itemprop\": \"ratingValue\"})[0].text.strip()\n",
    "    except IndexError:\n",
    "        rating_text = 0 \n",
    "    \n",
    "    #Extracting page particulars\n",
    "    page_divs = note_soup.find_all(\"div\", {\"class\": \"row\"})\n",
    "    try:\n",
    "        page_text = page_divs[0].find_all(\"span\", {\"itemprop\": \"numberOfPages\"})[0].text.strip(' pages')\n",
    "    except IndexError:\n",
    "        page_text = 0\n",
    "    \n",
    "    # When the book was published\n",
    "    publish_divs = note_soup.find_all(\"div\", {\"class\": \"uitext darkGreyText\", \"id\": \"details\"})\n",
    "    try:\n",
    "        publish_text = publish_divs[0].find_all(\"div\", {\"class\": \"row\"})[1].text.strip()\n",
    "        publish_text = publish_text.replace('\\n',' ')\n",
    "    except IndexError:\n",
    "        publish_text = 'Nil'\n",
    "\n",
    "    \n",
    "    #Extracting description particulars\n",
    "    description_divs = note_soup.find_all(\"div\", {\"class\": \"readable stacked\", \"id\": \"description\"})\n",
    "    try:\n",
    "        description_text = description_divs[0].find_all(\"span\")[1].text\n",
    "    except IndexError:\n",
    "        try:\n",
    "            description_text = description_divs[0].find_all(\"span\")[0].text\n",
    "        except IndexError:\n",
    "            description_text = \"Nil\"\n",
    "    #book_description.append(description_text)\n",
    "    \n",
    "    #adding to our dataframe\n",
    "    df_books.at[i,'author'] = author_text    \n",
    "    df_books.at[i,'rating'] = float(rating_text)   \n",
    "    df_books.at[i,'pages'] = page_text\n",
    "    df_books.at[i,'description'] = description_text.strip()\n",
    "    df_books.at[i,'published'] = publish_text.strip()\n",
    "    \n",
    "    #Incremeting the loop counter\n",
    "    i = i+1\n",
    "    #if i == 3 : break\n",
    "    if i in (100,200,300,400,500,600, 700, 800, 900, 1000, 1100, 1200):\n",
    "        print('No of books scraped so far: ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42fa1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there were some blanks in data that prevented the sort and groupby to work\n",
    "df_books['rating'].replace('', 0.0, inplace=True)\n",
    "df_books['pages'].replace('', 0.0, inplace=True)\n",
    "\n",
    "sorted_book_df = df_books.sort_values(['year','genre','rating'],ascending=(False, True, False))\n",
    "sorted_book_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0f70403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_book_df = sorted_book_df.groupby('year','genre','rating').head(5)\n",
    "tmp_book_df = sorted_book_df.groupby(['year','genre']).head(5) #.nlargest(5)\n",
    "tmp_book_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "997692dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_book_df = tmp_book_df.drop(columns='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42fbf31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_url</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>pages</th>\n",
       "      <th>year</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.goodreads.com/book/show/57178191-5...</td>\n",
       "      <td>5 Worlds Book 5: The Emerald Gate</td>\n",
       "      <td>children's</td>\n",
       "      <td>Mark  Siegel</td>\n",
       "      <td>4.67</td>\n",
       "      <td>272</td>\n",
       "      <td>2021</td>\n",
       "      <td>Published         November 16th 2021          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.goodreads.com/book/show/53420150-c...</td>\n",
       "      <td>Change Sings: a Children's Anthem</td>\n",
       "      <td>children's</td>\n",
       "      <td>Amanda Gorman</td>\n",
       "      <td>4.60</td>\n",
       "      <td>32</td>\n",
       "      <td>2021</td>\n",
       "      <td>Published         September 21st 2021         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.goodreads.com/book/show/55977822-w...</td>\n",
       "      <td>We Shall Overcome</td>\n",
       "      <td>children's</td>\n",
       "      <td>Bryan Collier</td>\n",
       "      <td>4.59</td>\n",
       "      <td>40</td>\n",
       "      <td>2021</td>\n",
       "      <td>Expected publication:         December 28th 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.goodreads.com/book/show/57375666-d...</td>\n",
       "      <td>Dancing with Daddy</td>\n",
       "      <td>children's</td>\n",
       "      <td>Anitra Rowe Schulte</td>\n",
       "      <td>4.51</td>\n",
       "      <td>40</td>\n",
       "      <td>2021</td>\n",
       "      <td>Published         December 1st 2021          b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.goodreads.com/book/show/53410874-b...</td>\n",
       "      <td>Barefoot Dreams of Petra Luna</td>\n",
       "      <td>children's</td>\n",
       "      <td>Alda P. Dobbs</td>\n",
       "      <td>4.49</td>\n",
       "      <td>288</td>\n",
       "      <td>2021</td>\n",
       "      <td>Published         September 14th 2021         ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            book_url  \\\n",
       "0  https://www.goodreads.com/book/show/57178191-5...   \n",
       "1  https://www.goodreads.com/book/show/53420150-c...   \n",
       "2  https://www.goodreads.com/book/show/55977822-w...   \n",
       "3  https://www.goodreads.com/book/show/57375666-d...   \n",
       "4  https://www.goodreads.com/book/show/53410874-b...   \n",
       "\n",
       "                               title       genre               author  rating  \\\n",
       "0  5 Worlds Book 5: The Emerald Gate  children's         Mark  Siegel    4.67   \n",
       "1  Change Sings: a Children's Anthem  children's        Amanda Gorman    4.60   \n",
       "2                  We Shall Overcome  children's        Bryan Collier    4.59   \n",
       "3                 Dancing with Daddy  children's  Anitra Rowe Schulte    4.51   \n",
       "4      Barefoot Dreams of Petra Luna  children's        Alda P. Dobbs    4.49   \n",
       "\n",
       "  pages  year                                          published  \n",
       "0   272  2021  Published         November 16th 2021          ...  \n",
       "1    32  2021  Published         September 21st 2021         ...  \n",
       "2    40  2021  Expected publication:         December 28th 20...  \n",
       "3    40  2021  Published         December 1st 2021          b...  \n",
       "4   288  2021  Published         September 14th 2021         ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_book_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dcaabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_book_df.to_csv(\".../TopFivePerGenre.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb8261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_book_df.to_csv(\".../NewReleases.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
